{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr6F6SQnw2ZW4KxRQAMh+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniel-falk/ai-ml-principles-exercises/blob/colab/ML-training/activeloop-deeplake/deeplake_imagenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with massive datasets\n",
        "This notebooks serves as an example to how easy it is to work with massive datasets when using DeepLake. The ImageNet training dataset is approximately 1TB in size. Since the DeepLake dataset only holds the metadata and fetches the images as they are needed, there is no need for massive amount of RAM or diskspace to store the dataset locally."
      ],
      "metadata": {
        "id": "jMYs9XLqGw0z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6mq54fTPHS5"
      },
      "outputs": [],
      "source": [
        "!pip install deeplake\n",
        "\n",
        "import deeplake\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hurry.filesize\n",
        "\n",
        "from hurry.filesize import size"
      ],
      "metadata": {
        "id": "HFhBok8VRUM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = deeplake.load('hub://activeloop/imagenet-train', token=\"REPLACE-ME\")"
      ],
      "metadata": {
        "id": "3wS5pZi0PQqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_size = 0\n",
        "for i, img in enumerate(tqdm(ds.images)):\n",
        "  total_size += img.numpy().size\n",
        "  if i % 1000 == 0:\n",
        "    print(f\"Total size is {size(total_size)} after {i+1} images counted\")"
      ],
      "metadata": {
        "id": "n8KcV0A3PTpE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}